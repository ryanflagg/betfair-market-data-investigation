{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> BF Dataset Cleaning and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>consolidateData(path)</h2><br>\n",
    "Method for combing the txt files in a folder to a single list of json objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 122\n",
      "2 of 122\n",
      "3 of 122\n",
      "4 of 122\n",
      "5 of 122\n",
      "6 of 122\n",
      "7 of 122\n",
      "8 of 122\n",
      "9 of 122\n",
      "10 of 122\n",
      "11 of 122\n",
      "12 of 122\n",
      "13 of 122\n",
      "14 of 122\n",
      "15 of 122\n",
      "16 of 122\n",
      "17 of 122\n",
      "18 of 122\n",
      "19 of 122\n",
      "20 of 122\n",
      "21 of 122\n",
      "22 of 122\n",
      "23 of 122\n",
      "24 of 122\n",
      "25 of 122\n",
      "26 of 122\n",
      "27 of 122\n",
      "28 of 122\n",
      "29 of 122\n",
      "30 of 122\n",
      "31 of 122\n",
      "32 of 122\n",
      "33 of 122\n",
      "34 of 122\n",
      "35 of 122\n",
      "36 of 122\n",
      "37 of 122\n",
      "38 of 122\n",
      "39 of 122\n",
      "40 of 122\n",
      "41 of 122\n",
      "42 of 122\n",
      "43 of 122\n",
      "44 of 122\n",
      "45 of 122\n",
      "46 of 122\n",
      "47 of 122\n",
      "48 of 122\n",
      "49 of 122\n",
      "50 of 122\n",
      "51 of 122\n",
      "52 of 122\n",
      "53 of 122\n",
      "54 of 122\n",
      "55 of 122\n",
      "56 of 122\n",
      "57 of 122\n",
      "58 of 122\n",
      "59 of 122\n",
      "60 of 122\n",
      "61 of 122\n",
      "62 of 122\n",
      "63 of 122\n",
      "64 of 122\n",
      "65 of 122\n",
      "66 of 122\n",
      "67 of 122\n",
      "68 of 122\n",
      "69 of 122\n",
      "70 of 122\n",
      "71 of 122\n",
      "72 of 122\n",
      "73 of 122\n",
      "74 of 122\n",
      "75 of 122\n",
      "76 of 122\n",
      "77 of 122\n",
      "78 of 122\n",
      "79 of 122\n",
      "80 of 122\n",
      "81 of 122\n",
      "82 of 122\n",
      "83 of 122\n",
      "84 of 122\n",
      "85 of 122\n",
      "86 of 122\n",
      "87 of 122\n",
      "88 of 122\n",
      "89 of 122\n",
      "90 of 122\n",
      "91 of 122\n",
      "92 of 122\n",
      "93 of 122\n",
      "94 of 122\n",
      "95 of 122\n",
      "96 of 122\n",
      "97 of 122\n",
      "98 of 122\n",
      "99 of 122\n",
      "100 of 122\n",
      "101 of 122\n",
      "102 of 122\n",
      "103 of 122\n",
      "104 of 122\n",
      "105 of 122\n",
      "106 of 122\n",
      "107 of 122\n",
      "108 of 122\n",
      "109 of 122\n",
      "110 of 122\n",
      "111 of 122\n",
      "112 of 122\n",
      "113 of 122\n",
      "114 of 122\n",
      "115 of 122\n",
      "116 of 122\n",
      "117 of 122\n",
      "118 of 122\n",
      "119 of 122\n",
      "120 of 122\n",
      "121 of 122\n",
      "122 of 122\n"
     ]
    }
   ],
   "source": [
    "marketData = consolidateData(\"E:/BFdata/Consolidated2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidateData(tgtDir):\n",
    "\n",
    "    counter = 0\n",
    "    fileList = []   \n",
    "    consolData = []\n",
    "    directory = tgtDir#\"E:/BFdata/Consolidated2\"\n",
    "\n",
    "##creates a list of files in the target directory\n",
    "    for fileName in os.listdir(directory):\n",
    "        fileList.append(fileName)    \n",
    "    listLen = len(fileList)\n",
    "    gc.enable()\n",
    "## builds the file paths and iterates over files in directory and opens each file\n",
    "    for file in fileList:\n",
    "        with open(directory + \"/\" + file) as f:   \n",
    "            counter = counter + 1\n",
    "            msg = (str(counter) + \" of \" + str(listLen))\n",
    "            print(msg)\n",
    "            marketData = jsonList(f)\n",
    "            consolData = consolData + marketData\n",
    "        \n",
    "    return consolData\n",
    "        ## converts each file object into JSON objects and appends to marketData list to create \n",
    "        ## 1x large consolidated listof json objects\n",
    "           \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonList(file):\n",
    "    for obj in file:\n",
    "        objList = []\n",
    "        marketUpdate = jsonConv(obj)\n",
    "        objList.append(listBuilder(marketUpdate))\n",
    "        return objList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jsonConv(file):\n",
    "    \n",
    "    #converts file into json object\n",
    "    \n",
    "    f = file\n",
    "    marketUpdate = json.loads(f)\n",
    "    return marketUpdate\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listBuilder(jsonObj):\n",
    "    \n",
    "    #builds list of json objects\n",
    "    \n",
    "    obj = jsonObj\n",
    "    objList = []\n",
    "    objList.append(obj)\n",
    "    return objList\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh dear this method uses rather a lot of RAM and crashes half way through!<br><br>\n",
    "concat the text files before using json.loads<br><br>\n",
    "find a way of writing the json obj to the hd so not taking up all the RAM.<br>\n",
    "<h3>Fixed! it turns out garbage collection is'nt envoked until the end of the function.  so splitting the process into three smaller functions solved the memory issues and drastically improved processing time.</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
